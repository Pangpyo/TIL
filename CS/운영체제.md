# 운영체제
### 운영체제의 역할은
* 자원관리 : CPU 스케줄링과 프로세스 관리, 메모리 관리, 파일 등 자원을 관리
* 자원 보호 : 프로그램이나 다른 사용자가 데이터를 삭제하거나 중요 파일에 접근하지 못하도록 자원을 보호
* 인터페이스 제공 : 하드웨어 인터페이스와 사용자 인터페이스를 제공하여 편리하게 사용하도록 지원
* 커널 : 컴퓨터 시스템의 핵심 부분으로, 하드웨어와 소프트웨어 사이의 중개자 역할을 함
## 메모리
### 메모리 계층
* 레지스터, 캐시, 주기억장치(RAM), 보조기억장치(SSD)
### 캐시 
* 데이터를 미리 볶사해 놓는 임시 저장소이자 빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리
* 캐시의 지역성
  * 시간 지역성 : 최근 사용한것을 캐시에 넣음
  * 실제 OS단에서 가져가는 데이터는 4KB단위.. 그러므로 하나의 값만 참조해도 근처 값을 같이 가져오게된다. 그래서 공간지역성에 의한 캐시가 가능한것
### 메모리 할당
* 페이징
  * 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당합니다
* 세그멘테이션
  * 페이지 단위가 아닌 의미(논리)단위인 세그먼트로 나누는 방식
### 페이지 교체 알고리즘
* FIFO 
  * 가장 먼저 온 페이지를 교체영역에 가장 먼저 놓는 방법
* LRU (Least Recently Used)
  * 참조된지 가장 오래된 페이지를 바꿈
* LFU (Least Frequently Used)
  * 가장 참조 횟수가 적은 페이지를 교체
* 캐시에서도 적용할 수 있다.
## 프로세스와 쓰레드
### 프로세스
* 운영체제로부터 자원을 할당받아 실행되고있는 작업의 단위
### 스레드
* 하나의 프로세스 내에서 동시에 진행되는 작업 갈래, 흐름의 단위
### 프로세스와 스레드의 자원 구조
* 프로세스
  * 코드영역, 데이터영역, 스택영역, 힙영역을 할당받아 사용함
  * 데이터영역과 코드영역은 정적으로 할당되며 컴파일 단계에 할당됨
  * 스택과 힙 영역은 런타임 단계에서 동적으로 할당 됨
  * 스택은 지역변수, 매개변수, 함수에 따라 늘어나거나 줄어듦
  * 힙은 동적으로 할당되는 변수들이 담김
  * 스택메모리가 힙 메모리보다 더 빠른 접근이 가능함
* 스레드
  * 프로세스 내에서 다른 자원들은 공유하며, 별도의 스택영역만을 할당받음
### 컨텍스트 스위칭
* 프로세스(쓰레드)에서 다른 프로세스(쓰레드)로 전환하는 것. 프로세스의 상태를 저장하고 로드해야한다.
* 스레드는 스택영역을 제외한 모든 메모리를 공유하기 때문에 프로세스의 컨텍스트 스위칭보다 더 적은 비용과 시간을 소요한다.
## 공유자원과 임계영역
### 공유자원
* 시스템 안에서 각 프로세스, 스레드가 함께 접근 할 수 있는 자원이나 변수. 이 공유자원을 두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황을 경쟁상태라고 한다.
### 임계영역
* 둘 이상의 프로세스, 스레드가 공유자원에 접근할 때 순서 등의 이유로 결과가 달라지는 코드영역
### 뮤텍스, 세마포어, 모니터
* 이 세가지 방법을 통해 임계 영역을 해결 가능하다.
* 이 세가지 방법 모두 상호 배제, 한정대기, 융통성을 만족한다
* 상호 배제 : 한 프로세스가 임계영역에 들어갔을 때 다른 프로세스는 들어갈 수 없다
* 한정 대기 : 특정 프로세스가 영원이 임계영역에 들어가지 못하면 안된다
* 융통성 : 만약 어떠한 프로세스도 임계영역을 사용하지 않는다면 임계영역 외부의 어떠한 프로세스도 들어갈 수 있으며 이 때 프로세스끼리 방해하지 않는다
* 뮤텍스
  * 공유 자원을 잠금 설정하여 사용 한 후 잠금 해제하는 방법(하나의 대상만이 자원에 접근 가능)
* 세마포어
  * 공유 자원에 대한 접근을 신호를 통해 제어. 카운트를 통해 진입 가능한 프로세스, 스레드의 수를 조절 가능하다

## 교착상태
* 교착상태(deadlock)는 두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태이다.
### 교착상태의 원인
* 상호 배제 : 한 프로세스가 자원을 독점하고 있으며 다른 프로세스들은 접근이 불가능
* 점유 대기 : 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하는 상태
* 비선점 : 다른 프로세스는 자원을 강제적으로 가져올 수 없습니다.
* 환형 대기 : 프로세스 A는 프로세스 B의 자원을 요구하고, 프로세스 B는 프로세스 A의 자원을 요구하는, 서로의 자원을 요구하는 상황

### 교착상태의 해결 방법
* 예방 : 요구조건을 만족시키지 않게 함으로서 교착상태 방지, 자원 낭비가 심함
* 회피 : 교착상태가 발생할 가능성을 배제하지 않고 발생하면 적절히 피해나감, 교착상태가 발생할 가능성이 있는 자원할당을 하지 않음
* 탐지 및 회복 : 교착상태가 발생 하면 그 후 고침(프로세스 중지 등)

## CPU 스케줄링 알고리즘
* CPU 스케줄러는 CPU 스케줄링 알고리즘에 따라 프로세스에서 해야 하는 일을 스레드 단위로 CPU에 할당합니다.
### 비 선점형 방식
* FCFS(선입선출)
  * 가장 먼저 온 것을 가장 먼저 처리하는(큐) 알고리즘
* 우선순위
  * 오래 된 작업일수록 우선순위를 높여 처리하는 알고리즘
### 선점형 방식
* 라운드 로빈
  * 현대 컴퓨터가 쓰는 알고리즘, 각 프로세스는 동일한 할당시간을 주고 그 시간 안에 끝나지 않으면 다시 준비 큐의 뒤로 가는 알고리즘.
  * 할당 시간이 너무 크면 FCFS에 수렴하고, 너무 짧으면 컨텍스트 스위칭이 잦아짐
* 다단계 큐
  * 우선순위에 따른 준비 큐를 여러개 사용하고, 큐마다 다른 스케줄링 알고리즘을 적용한 것.

## 멀티태스킹
### 동기와 비동기
* 요청한 작업에 대해 완료 여부를 신경써서 작업을 순차적으로 수행할지 아닌지에 대한 관전
  * 완료 여부를 기다리고 그를 다음 작업에 반영하므로 동기화됐다고 할수 있다
### 블로킹과 논블로킹
* 현재 작업이 블록(차단) 되느냐, 아니냐에 대한 관점
  * 논블로킹일 경우 현대 작업이 차단되지 않고(계속 작업하면서) 다른 작업을 수행

### 동기/비동기 + 블로킹/논블로킹 조합
* 동기 + 블로킹
  * 다른 작업이 진행되는 동안 자신의 작업을 처리하지 않고, 다른 작업의 완료 여부를 받아 순차적으로 처리하는 방식. 다른 작업의 결과가 자신의 작업에 영향을 주는 경우 활용
* 비동기 + 논블로킹 방식
  * 다른 작업이 진행되는 동안에도 자신의 작업을 처리하고, 다른 작업의 결과를 바로 처리하지 않아 작업 순서가 지켜지지 않는 방식
* 동기 + 논블로킹 방식
  * 다른 작업이 진행되는 동안에도 자신의 작업을 처리하고, 다른 작업의 결과를 바로 처리하여 작업을 순차대로 수행 하는 방식
  * 사용예시로는 A 프로그램을 실행하는 도중 B 프로그램을 로드 할 때, A프로그램은 B프로그램의 로드하는동안의 진행률을 보여준다. 이로써 A프로그램은 자신의 작업을 처리하고있지만, B프로그램의 로드를 기다려야한다.

## 시스템 콜이 무엇인지 설명해 주세요.
* 운영 체제의 커널이 제공하는 서비스에 대해 응용 프로그램이 커널에 접근하기 위한 인터페이스. 운영체제에게 명령의 대행을 요청한다.
### 시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.
1. 응용 프로그램이 유저모드에서 시스템 콜 호출
2. 프로세스가 유저모드에서 커널 모드로 전환
3. 시스템 콜 번호 확인 및 처리
4. 유저모드로 복귀
### 우리가 사용하는 시스템 콜의 예시를 들어주세요.
* open(), read(), write(), close(), fork(프로세스 생성), exec(현재 프로세스 대체), wait(프로세스가 자식 프로세스의 실행이 끝날 때 까지 기다리게 함), exit(프로세스 종료), kill(특정 프로세스 종료)과 같은 함수들이 있다.
* 우리가 파일을 열거나, 닫고, 쓰는 작업들은 시스템 콜이다.
### CPU가 유저모드, 커널모드를 구분하는 방법
* 플래그 레지스터 내에 슈퍼바이저 플래그가 1일 경우 커널모드, 0일 경우 사용자 모드.
### 시스템 콜의 유형에 대해 설명해 주세요.
* 프로세스 제어, 파일 조작, 장치관리, 정보 유지, 통신, 보호 등이 있다.
### 운영체제의 Dual Mode 에 대해 설명해 주세요.
* 시스템의 보안과 안정성을 유지하기 위해 유저모드, 커널모드라는 두 가지 모드를 사용하는 것.
* 유저모드 : 일반적인 응용 프로그램이 실행되는 모드. 제한된 접근 권한을 가지고 있어 시스템의 중요한 부분에 접근 할 수 없다.
* 커널 모드 : 운영체제의 커널이 실행되는 모드로, 시스템의 모든 자원에 대한 완전한 접근 권한을 가진다. 이 모드에서 시스템 콜이나 인터럽트 처리 등이 수행된다.
### 왜 유저모드와 커널모드를 구분해야 하나요?
* 시스템의 보안과 안정성을 유지하기 위해 유저모드를 두어 시스템의 중요한 부분에 접글 할 수 없도록 한다.
### 서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?
* 커널은 내부적으로 각각의 시스템 콜을 구분하기 위해 기능별로 고유 번호를 할당하고 그 번호에 해당하는 제어 루틴을 커널 내부에 정의한다.
### 유저모드에서 시스템 콜의 번호를 어떻게 전달하나?
* 레지스터에 전달하거나, 크기가 크다면 메모리에 쓰고 메모리 주소를 레지스터에 전달

## 인터럽트가 무엇인지 설명해 주세요.
* 인터럽트란 예외상황이 발생하여 현재 실행 중인 작업을 즉시 중단하고 발생한 상황에 대한 우선 처리가 필요함을 CPU에 알리는 것이다.
### 인터럽트는 어떻게 처리하나요?
1. 인터럽트 요청을 받으면 현재 실행중인 상태를 중단한다.
2. 현재의 작업 상태를 스택에 저장한다.
3. 인터럽트 벡터 테이블을 참조하여 해당 인터럽트에 대응하는 인터럽트 서비스 루틴을 실행한다.
4. 인터럽트 처리를 한 후, 저장된 CPU 상태를 복원하고 중단된 프로그램의 실행을 계속한다.
### 인터럽트 서비스 루틴이란?
* 인터럽트가 발생하면 어떻게 처리할지 정해져있는 운영체제 내의 기계어 코드.
### Polling 방식에 대해 설명해 주세요.
* 하나의 장치가 다른 장치의 상태를 주기적으로 검사하여 일정한 조건을 만족할 때 처리를 하는 방식. 인터럽트는 장치가 cpu에게 신호를 보내고, 폴링은 cpu가 다른 장치를 확인한다는 차이점이 있다.
### HW / SW 인터럽트에 대해 설명해 주세요.
* HW : 하드웨어 장치로부터 발생하여, 키보드 입력이나 네트워크 패킷 수신 등이 해당한다.
* SW : 특정 명령어의 실행에 의해 발생하며, 주로 운영체제의 시스템 콜을 처리할 때 사용된다. 혹은 0나누기 연산이나 잘못된 메모리 접근 등에서도 발생한다.
### 동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?
* 인터럽트 우선순위에 따라 진행하며, 현재 인터럽트가 처리중인데 더 높은 우선순위의 인터럽트가 실행되면 현재 인터럽트를 중단하고 새로운 인터럽트를 처리하고, 이후 이전의 인터럽트를 처리하게 된다.
### 인터럽트 우선순위는 어떻게 정해지나요?
* 인터럽트 우선순위는 HW적인 방법과 SW방법이 있다. HW적으로는 인터럽트가 발생하는 장치를 직렬로 연결된 회선으로 선두에 있는 장치가 높은 우선순위의 장치로 판별할 수 있다. SW적으로는 폴링방식으로 정해진다. 먼저 검사한 인터럽트가 우선순위가 높다.

## 프로세스가 무엇인가요?
* 컴퓨터에 의해 실행되고 있는 프로그램의 인스턴스. 실행에 필요한 코드, 데이터, 시스템 자원 등이 포함된다.
### 프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.
* 프로그램 : 코드의 집합, 디스크 안에 저장되어있다.
* 프로세스 : 실행 중에 있는 프로그램, 운영체제로부터 실행에 필요한 자원을 할당받은 상태. 독립적인 code, data, stack, heap 메모리 공간을 가지고 있음
* 쓰레드 : 프로세스 내에서 실행되는 여러 흐름의 단위
### 프로세스와 쓰레드중 실제로 명령어를 수행하는 것은?
* 쓰레드가 프로세스 내에서 실제로 작업을 수행하는 실행 단위이다.
### PCB가 무엇인가요?
* Process Control Block : 운영체제가 프로세스를 제어하기 위해 정보를 저장해놓은 곳. 프로세스가 생성될 때 마다 고유의 PCB가 생성된다. 프로세스의 상태관리와 context swiching을 위해 필요하다. 커널 영역에 저장된다.
* PID, 부모 PID, 상태 정보, 다음 실행 명령어, 레지스터 정보, 메모리 정보 등을 저장한다.
### 그렇다면, 스레드는 PCB를 갖고 있을까요?
* 쓰레드 또한 PCB내부에 있는 TCB(쓰레드 컨트롤 블럭)을 가지고 있다. TCP는 스택 포인터, 스레드 식별자와 상태 등을 가지고 있고, 메모리 관련 정보가 없다.
### 리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?
* 프로세스 : fork()를 통해 자식 프로세스 생성, exec()을 통해 다른 작업으로 변경
* pthread_create()를 통해 프로세스 생성
### 자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?
* 고아 프로세스 : 부모 프로세스가 자식 프로세스보다 먼저 죽은 경우
  * 프로세스가 죽을 때 해당 프로세스가 어떤 프로세스의 부모 프로세스인지 확인 후 init 프로세스로 부모 프로세스를 옮김
  * 혹은 init 프로세스가 부담된다면 손자가 고아가 됐을때, 회수한다.(subreaper)
* 좀비 프로세스 : 자식 프로세스가 부모 프로세스가 먼저 죽은 경우
  * 커널은 자식 프로세스가 종료 프로세스 테이블에 여전히 남아있으며, 부모 프로세스가 wait() 을 통해 종료상태를 회수하면 좀비 프로세스가 제거된다.
### 리눅스에서, 데몬프로세스에 대해 설명해 주세요.
* 사용자의 직접적인 개입 없이 백그라운드에서 실행되며 특성 서비스를 제공하는 프로세스. 시스템이 부팅될 때 자동으로 시작된다. 리눅스에서는 `httpd`, `sshd`, `mysqld` 등이 있다. 자식 프로세스를 포크하여 생성하고, 자식을 분기한 자신을 죽이면 init이 고아가 된 자식프로세스를 init 밑으로 데려간다. 이 떄 setsid()을 호출하여 세션 리더가 되어 터미널 제어권이 분리된다. 이로써 데몬 프로세스가 생성된다.
### 리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.
* 시스템 부팅 시 가장 먼저 시작되는 프로세스, `init` 또는 `systemd`이다. PID 1번을 가지며, 시스템의 부팅, 실행, 종료를 관리한다.


## 프로세스 주소공간에 대해 설명해 주세요.
* 프로세스가 운영체제로부터 할당받는 메모리 영역
* code : 프로그램의 명령어들이 위치하는 공간, 컴파일시 결정됨. 읽기 전용이며, 속도가 빠르고, 여러 인스턴스가 공유할 수 있다. 
* data : global, static 변수가 저장되는 영역으로 프로그램 실행 동안 지속적으로 유지되어야 하는 데이터, 컴파일시 결정됨. BSS세그먼트를 포함한다. 
* stack : 함수의 호출과 반환에 사용되며, 매개변수, 반환주소 등이 저장된다. LIFO 방식으로 관리된다. 컴파일시 결정된다. 높은주소에서 낮은 주소로 할당된다.
* heap : 프로그램 실행 중에 동적으로 할당하고 해제 할 수 있는 메모리 영역. 런타임중에 필요에 따라 할당되고 해제되며, 낮은 주소에서 높은 주소의 방향으로 할당된다. class와 class의 객체들이 이곳에 저장된다.(참조값)
### 초기화 하지 않은 변수들은 어디에 저장될까요?
* BSS(Block started by symbol)영역에 저장되고, 변수가 실제로 사용되기 전까지 메모리에 할당되지 않는다.
### final 변수는 어디에 저장될까요?
* final 변수는 rodata영역
### 일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?
* 편의상 그렇게 그렸지만, 프로그램에 따라 그렇지 않을 수 있다. 스택은 컴파일시 정해지며, 힙은 필요에 따라 동적으로 할당된다.
### Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?
* Cpu가 직접 관리하고 최적화 하기 때문에 stack이 빠르다.
### 다음과 같이 공간을 분할하는 이유가 있을까요?
* 메모리 관리의 효율성과 안정성을 높이기 위해 사용되며, 데이터를 공유하여 메모리 사용량을 줄일 수 있다.
### 스레드의 주소공간은 어떻게 구성되어 있을까요?
* 프로세스 내에서 각각의 스택만 할당 받고 나머지 영역은 공유한다.
### "스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.
* 스택영역은 실제 자료구조의 스택과 같은 방식인 LIFO로 작동한다.
* 힙 영역은 실제 자료구조 힙과 큰 관련이 없다.
### IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?
* ICP : Inter-Process Communication : 프로세스간에 데이터를 주고받거나 동기화하는 메커니즘.
* Shared Memory : 여러 프로세스가 동시에 접근 할 수 있는 메모리 영역. 배열을 사용하기 때문에 데이터 영역에 위치한다. 
### 스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?
* 스택 영역과 힙 영역 모두 컴파일시에 결졍된다. 특정 환경에서는 사용자가 스택의 크기를 변경할 수 있으나, 신중하게 수행되어야 한다.
### 스택과 힙중 더 빠른 영역은
* 스택에서 힙을 참조하기 때문에 힙보다 스택이 더 빠르다. 스택이 캐시 활용도가 더 높다. 메모리의 할당과 해제가 스택 포인터를 이동하는 것으로 이루어지기에.


## 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.
* 단기 : 준비 상태의 프로세스를 다음번 실행상태로 만들 것인지 결정하는 스케줄러.
* 중기 : 스와핑 스케줄러라고 불리며, 시스템의 성능 저하를 방지하기 위해 메모리에 적재된 프로세스 수를 조절합니다.
* 장기 : 시스템에 새로운 프로세스를 언제 도입할지 결정. 수십 초에서 수분 단위로 작동 할 수 있다.
### scheduler와 dispatcher의 개념을 알고 있나요 
* 스케줄러 : 프로세스의 상태를 결정하는 것.
* 디스패쳐 : 스케줄러에 의해 선택된 프로세스를 cpu에서 실행될 수 있도록 하는 것
### 현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?
* 현대에는 장기 스케줄러는 사용하지 않는다. 메모리 크기 증가와 가상 메모리 관리 기술에 따라 메모리 사용이 원활해 졌기 때문.
### 프로세스의 스케쥴링 상태에 대해 설명해 주세요.
* Created : 프로세스가 생성되었지만, 아직 준비 큐에 들어가지 않은 상태
* New : 생성 후 준비 중인 상태
* Ready : 프로세스가 준비가 완료된 상태 CPU 할당을 기다리는 상태
* Running : 프로세스가 CPU를 할당받아 명령어를 실행하고 있는 상태
* Wating : 프로세스가 대기중인 상태
* Suspended : 프로세스가 메모리자원이 부족하여 스왑 아웃되어 디스크에 저장된 상태
* Terminated : 프로세스가 실행을 완료하고 제거된 상태
### preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?
* 선점적 스케줄링 : 운영 체제가 실행 중인 프로세스를 언제든 상태가 변화 될 수 있다.
* 비선점적 스케줄링 : 실행 중인 프로세스는 선점되지 않으며, 다른 프로세스가 CPU를 해제할 때 까지 기다려야한다. 그러므로 실행에서 준비로 돌아가지 못한다.
### Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?
* 스왑 아웃되어 디스크에 저장되고, ready나 waiting으로 전환된다.

## 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?
* 실행중인 상태를 PCB(프로세스 상태 블록)에 업데이트하여 스택에 저장
* 스케줄러가 스케줄링 알고리즘에 따라 다음 실행할 프로세스를 PCB에서 불러와서 running
* 새로운 프로세스가 이전 프로세스의 메모리 주소를 잘못 사용하지 않도록 캐시 클리어
### 프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?
* 쓰레스는 공유하는 영역이 많아 TCB(쓰레드 상태 블록)에는 stack메모리와 간단한 레지스터 포인터만 저장하기 때문에 더 빠르다.
* 일부 정보만 변경되므로 캐시 클리어가 일어나지 않는다.
### 컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?
* 스택프레임(현재 프로세스의 CPU 레지스터 상태, 다음 실행 명령어 주소 등의 데이터) 형태로 커널 스택에 push하여 저장한다. Pcb에는 이 커널스택의 top 포인터를 저장한다. 이후 기존 프로세스로 전환 할 때 pop하여 복원한다.
### 프로세스 주소 공간에서 커널 영역은 어떤 공간인가요?
* 메모리중 0~3gb는 사용자 공간, 3~4gb는 커널 공간이다. 모든 프로세스가 공유하며, 커널이 실행되는 공간이다.
### 커널 공간은 프로세스들이 각각 가지고 있나요?
* 모든 메모리들이 공유한다.
### 컨텍스트 스위칭은 언제 일어날까요?
* Ready > Running
* Running > Ready
* Running > Waiting

## 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요?
비선점형 방식
* FCFS(선입선출)
  * 가장 먼저 온 것을 가장 먼저 처리하는(큐) 알고리즘
* 우선순위
  * 작업마다 우선순위가 주어지며, 우선순위가 가장 높은 작업이 먼저 처리된다.
선점형 방식
* 라운드 로빈
  * 현대 컴퓨터가 쓰는 알고리즘, 각 프로세스는 동일한 할당시간을 주고 그 시간 안에 끝나지 않으면 다시 준비 큐의 뒤로 가는 알고리즘. 동시성을 가진다.
  * 할당 시간이 너무 크면 FCFS에 수렴하고, 너무 짧으면 컨텍스트 스위칭이 잦아짐
* 다단계 큐
  * 우선순위에 따른 준비 큐를 여러개 사용하고, 큐마다 다른 스케줄링 알고리즘을 적용한 것.
* Multi-level Feedback Queue
  * 우선순위를 기반으로 스케줄링 진행, 오랫동안 할당 안된 프로세스의 우선순위를 높임. 동시성을 가질 수 있다.
### 프로세스를 스케줄링하기 위해 운영체제가 관리하는 큐의 종류에 어떤게 있나요?
* 현재 시스템의 모든 프로세스의 집합인 job queue, 준비중인 ready queue, device queue, wait queue
### 운영체제는 각 큐를 어떻게 접근할 수 있을까요
* 각 큐에 포인터로 접근
### RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.
* 할당 시간이 크면 FCFS에 수렴하고, 너무 짧으면 컨텍스트 스위칭이 잦아진다.
### 싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?
* RR, MLFQ 같은 동시성을 가지는 스케줄링 알고리즘을 사용하는 것이 좋다.
### 동시성과 병렬성의 차이에 대해 설명해 주세요.
* 동시성 : 여러 작업이 동시에 실행되는 것처럼 스케줄링을 하는 것. 빠른 전환을 통해 구현된다. 싱글코어 CPU에서도 사용 될 수 있다.
* 병렬성 : 실제로 여러 작업이 동시에 실행되는 것. 멀티 코어 CPU에서 사용 할 수 있다.
### 타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?
* 우선순위 알고리즘과 비교했을 때, 우선순위가 낮은 프로세스가 무한히 대기상태에 들어가는 문제점을 해결 하였다.
  * 운영체제에서 우선순위가 낮은 프로세스의 특징 : 데몬 프로세스, non-대화형 프로세스
### FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?
* 작업 시간이 모두 비슷한 프로세스들의 경우에는 효과적이다.
### 우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?
* 우선순위, 라운드 로빈 등 유사한 방식을 가진다.
### 유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?
* 다르다. 유저 쓰레드는 운영체제의 커널이 직접 관리하지 않고, 사용자 수준에서 관리된다.

## 뮤텍스와 세마포어의 차이점은 무엇인가요?
* 뮤텍스는 단 하나의 대상만이 자원에 접근 가능하며, 세마포어는 설정에 따라 그 이상이 접근 가능 하다. 또한 뮤텍스는 잠금 메커니즘이고, 세마포어는 신호 메커니즘이다.
### 이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.
* 두 가지 모두 하나의 대상만이 자원에 접근 가능하지만, 뮤텍스는 그 것을 자원에 대한 접근을 잠금으로 가능하게 하고, 세마포어는 신호를 0으로 만듦을 통해 가능하게 한다. 또한 세마포어는 프로세스 내의 다른 쓰레드가 잠금을 해제 할 수 있지만, 뮤텍스는 그렇지 않다. 그렇기에 속도가 더 빠르다.
### Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?
* spin lock : 진입이 불가능 할 때, 진입이 가능 할 때 까지 루프를 돌면서 재시도하는 방식. 콘텍스트 스위칭이 일어나지 않아 빠르게 작동한다. lock-unlock 과정이 짧을때 효과적이다. 하지만 실행 순서를 보장하지 않고 대기 시간을 보장받지 못하기에, 기아 상황이 발생 할 수 있다. 티켓 기반 스핀락으로 순서를 보장할 수 있다. 하지만 티켓을 기반으로 할 경우 프로세스가 많아지면 성능은 떨어질 수 있다.
* block-lock(뮤텍스, 세마포어)은 wait, notify등으로 무한히 대기하진 않지만 context switching이 발생함.
### 뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?
* 커널이 락을 관리하기에 안정하고, 일관성있다. 하지만 시스템 콜을 호출하는 과정에서 오버헤드, 컨텍스트 스위칭, 블로킹 등으로 시간이 소요될 수 있다. 이를 해결하기 위해 사용자 레벨에서 락을 구현하여 이런 단점을 해결해 볼 수 있다.

## Deadlock 에 대해 설명해 주세요.
* 두개 이상의 프로세스가 서로가 가진 자원을 기다리며 중단된 상태
### Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.
* 상호 배제(Mutual Exclusion) : 자원은 한 번에 한 프로세스만 사용할 수 있어야 한다.
* 점유 대기(hold and wait) : 최소한 하나의 자원을 점유하고 있으면서 다른 프로세스에 할당되어 사용하고 있는 자원을 추가로 점유하기 위해 대기하는 상태이다.
* 순환 대기(circular wait) : 프로세스가 원형으로 서로의 자원을 요구하고 있어야 한다.
* 비선점(no preemitive) : 다른 프로세스에 할당된 자원은 사용이 끝날 때까지 강제로 빼앗을 수 없어야 한다.

### 그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?
* 네가지 조건을 모두 충족하지 않는 경우, 언젠가 자원을 얻을 수 있다. 4개가 모두 필요조건으로 만족해야만 한다.
### 어떤 방식으로 예방할 수 있을까요?
* 상호 배제 방지 : 자원을 한 번에 여러 프로세스가 공유할 수 있도록 허용
* 점유 대기 방지 : 프로세스가 실행에 필요한 모든 자원을 한번에 요구하도록 한다.
* 비선점 방지 : 자원에 대한 선점을 허용한다.
* 순환 대기 방지 : 자원에 순서부여를 통해 순서를 따라 지원을 요청하도록 한다.
* 다만 위의 조건들을 사용할 경우 동시성문제나 자원 낭비가 발생할 가능성이 있다.
### 왜 현대 OS는 Deadlock을 처리하지 않을까요?
* 자원 낭비 : 위의 조건들은 모두 리스크를 동반하기에, 빈번히 발생하지 않는 상황에 대해 데드락을 처리하지 않는 것이 더 낫다고 판단해서.
### Dead Lock 감지하는 방법
* 자원 할당 그래프에서 사이클이 발생하면 데드락이 발생한 것을 감지할 수 있다.
* 자원 할당 그래프 : 자원간의 할당 상태를 나타내는 방법.
### Wait Free와 Lock Free를 비교해 주세요.
* lock free : 적어도 하나의 스레드가 임의의 시간동안 유한한 단계 내에 진행되는 것을 보장. 데드락이 발생하지 않고, 최소 하나의 스레드가 진행할 수 있다.
* wait free : 모든 호출이 유한한 단계 내에서 진행되는 것을 보장하는 것. 락 프리보다 더 강력한 조건이다.
* 이를 위해 CAS(Compare and Swap)이 필요하다.


## 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.
0. 소스코드 작성
1. 전처리 : 소스파일 상 주석 제거, 헤더 파일 코드 삽입
2. 컴파일 : 어셈블리어로 번역
3. 어셈블 : 기계어로 번역
4. 링커 : 사용한 다른 오브젝트 파일을 통합하여 실행 파일을 생성한다.
5. 로더 : 실행 파일을 가져와 메인 메모리에 로드하여 실행되도록 한다.
### 링커와, 로더의 차이에 대해 설명해 주세요.
* 링커 : 프로그램의 오브젝트 모듈을 결합하여 실행 모듈 생성
* 로더 : 이 실행 모듈을 메인 메모리에 로드하여 실행
### 컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.
* 컴파일 언어 : 컴파일 과정을 통해 한번에 기계어로 변환한다. 초기 실행시간이 오래걸리지만, 이후 실행시간이 빠르다. 실행 파일을 생성하기 때문.
* 인터프리터 언어 : 소스코드를 한줄씩 읽어들여 변환한다. 실행파일을 생성하지 않기에 메모리 효율적이지만, 직접 실행하기에 초기 속도가 빠르고 전반적으로 느리다.
### JIT에 대해 설명해 주세요.
* Just In Time의 약자이다. 소스코드를 바이트 코드로 컴파일한다. 바이트 코드는 가상머신에 의해 빠르게 기계어로 변환할 수 있는 코드이다. 이를 인터프리트 방식으로 읽어, 필요한 부분만을 실행한다.
### 본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.
* Java : 소스코드를 바이트코드로 변환하여 `.class`파일로 저장된다. 이후 JVM은 실행할 클래스를 찾아 메모리에 로드하고, 바이트코드를 인터프리터 방식으로 해석하여 실행한다.
* Python : 파이썬 인터프리터가 소스 코드를 한 줄씩 읽어들여 실행하며, 실행 시점에 바이트코드를 생성한다.
### Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?
* CPython은 인터프리터 방식으로 실행되며, GIL(글로벌 인터프리터 락)이 걸려있어 하나의 스레드만 코드를 실행할 수 있다. PyPy는 JIT컴파일을 통해 실행한다.

### 우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?
* 로더는 이러한 시스템 콜과는 직접적으로 관련 없다. 프로세스를 적재하는 것이 아닌, 메모리에 실행 파일을 로드하기 때문이다.

## IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.
* Inter Process Communication : 프로세스 간 통신. 
* Message Passing : 커널이 제공하는 API를 이용해서 커널 공간을 통해 통신. 메시지 큐를 사용하여 송신 프로세스는 큐에 엔큐, 수신 프로세스는 큐에 데큐하며 상호간 통신한다. 파이프와 소켓도 이 방법에 속한다.
* Shared Memory : 프로세스끼리 특정 공통의 메모리 영역을 공유하며 상호간 통신. 
### Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.
* 프로세스간에 메모리가 공유되므로 동기화에 유의해야한다. 자원에 접근에 대해 주의해야한다.
### IPC가 사용되는 구체적인 사례 / 사용해본 경험를 말씀해주세요
* web server, was와의 통신 또한 IPC를 사용한다.
### 메시지 큐는 단방향이라고 할 수 있나요?
* 하나의 메시지 큐는 단방향이지만, 두 개 이상의 메세지 큐를 사용함으로써 양방향 통신을 구현 할 수 있다.

## Thread Safe 하다는 것은 어떤 의미인가요?
* 멀티 쓰레드 프로그래밍에서, 자원이 여러 스레드로부터 동시에 접근되어도 프로그램 실행에 문제가 없음을 의미한다.
### Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?
* 변경 불가능한 객체를 만들거나, 세마포어, 뮤텍스와 같은 상호배제를 구현할 수 있다.
### Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.
* 뮤텍스를 구현하기 위한 알고리즘 중 하나이다. 자원이 사용 가능한지 확인함으로써 이뤄낼 수 있다. 프로세스가 2개인 경우 사용 가능하고, 세개 이상은 논의되고 있다. 또한 대기시간동안 불필요한 계산을 수행하기에, CPU자원이 낭비 될 수 있다.
### Race Condition 이 무엇인가요?
* 둘 이상의 스레드나 프로세스가 공유 자원을 동시에 접근하고 변경 할 때, 의도와 달라질 수 있는 상태.
### Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?
* 스레드별 로컬 변수 사용, 이뮤터블 객체 사용, 원자연산 등을 통해 락을 걸지 않고도 스레드 세이프한 코드를 짤 수 있다.

## Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.
* Thread Pool : 스레드를 필요할 때 생성하고 필요 없을 때 삭제하는 것이 아닌, 스레드를 제한된 개수만큼 미리 생성해두고 작업 큐에 들어오는 작업들을 하나씩 스레드가 맡아 처리하는 방식.
* Monitor : 뮤텍스에 Condition Variable을 가지고 있는 동기화 메커니즘. 락을 획득하고 해제하는 동작을 내부적으로 처리한다. 프로시저를 하나의 단위로 캡슐화한다. 자바는 Object 클래스가 모니터를 통해 상호배제를 구현한다.
* Fork-Join : 병렬 처리를 위한 기능, 분할 정복 알고리즘을 통해 재귀적으로 처리된다. 작업을 여러개로 나누어 동시에 실행시키고, 결과를 모으는 방식이다.
### Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요?
1. CPU 코어 수, 메모리 등 하드웨어 스펙에 따라 스레드의 수를 늘릴 수 있다.
2. 응답 시간이 중요한 경우, 자원을 많이 차지하더라도 스레드의 수를 늘리는 것이 좋다.
3. 자원을 절약해야 하는 경우, 스레드의 수를 제한하는 것이 좋다.
4. 병렬 처리가 많은 작업의 경우 스레드의 수가 많은 것이 좋다.
### 어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?
* 멀티 스레드 환경에서는 병합 정렬을 고려해 볼 수 있다. 병합정렬은 분할정복 알고리즘을 사용하기에, 멀티 스레드를 사용한 병렬 처리에 유리하다. 단일 스레드 환경에서는 퀵 정렬과 같은 캐시히트가 좋은 정렬이 좋을 수 있다. 퀵 정렬의 경우 불안정 정렬이기에 기존 객체의 순서가 바뀔 수 있고, 최악의 경우 속도가 N^2까지 느려질 수 있다.

## 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.
* 캐시메모리 : 자주 사용하는 데이터를 빠르게 접근 할 수 있도록 저장한 메모리.
* 레지스터 : CPU 내부에 위치하며 가장 빠른 메모리. 프로세서가 직접 접근 할 수 있어 매우 빠르다.
* 캐시 메모리 : CPU와 주기억 장치 사이에 있으며, 자주 사용되는 데이터를 복사해두어 사용한다. 작고 빠르다.
* 주 기억장치 : CPU 외부에 존재하며, CPU가 직접 접근할 수 있다. 대부분이 프로그램이 여기서 실행된다.
* HDD, SSD와 같은 메모리, CPU가 직접 접근할 수 없다.
### 캐시 미스의 종류
* 프로그램 실행 초기에 발생하는 콜드 스타트 미스
* 캐시의 용량이 충분하지 않아 발생하는 capacity miss
* 캐시끼리 충돌하여 발생하는 conflict miss
### 캐시 메모리는 어디에 위치해 있나요?
* L1은 CPU 내부, L2는 CPU 회로판에 별도의 칩으로, L3는 메모리와 CPU 사이에 존재한다.
### L1, L2 캐시에 대해 설명해 주세요.
* L1 : CPU 내부에 있고, 가장 먼저 참조에 이용된다. 가장 빠르다.
* L2 : L1보다 조금 느리고, CPU 회로판에 별도의 칩으로 내장되어 있다.
* L3 : 여러 코어가 공유하며, L1, L2 캐시보다 더 크고 느리다.
### 캐시에 올라오는 데이터는 어떻게 관리되나요?
* 주소와 키로 주어지면 해당 공간에 즉시 접근 가능하다. 캐시를 저장 할 때 캐시가 만료되는 시간을 명시한다.
### 캐시간의 동기화는 어떻게 이루어지나요?
* MESI 프로토콜 : Modified(수정됨), Exclusive(독점), Shared(공유), Invalid(무효)의 네 가지 상태를 통해 관리한다.
* 스누핑 : 메모리에 쓰기 연산을 할 시 해당 연산은 버스를 통해 모든 프로세서에게 알리고, 다른 프로세서는 이 알림을 통해 해당 메모리 위치를 캐시하고 있으면 그 내용을 무효화하거나 업데이트한다.
* 디렉토리 캐시 동기화 : 각 캐시 라인의 상태를 보관중인 디렉토리라는 데이터 구조를 사용한다. 대규모에서 사용된다.
### 캐시 메모리의 Mapping 방식에 대해 설명해 주세요.
* direct_mapping : 각 캐시 라인은 하나의 캐시 블록을 가지고, 메모리 주소를 캐시 라인에 직접 매핑한다. 간단하지만 충돌이 잦다.
* Fully Associative : 메모리 주소를 캐시 블록에 자유롭게 매핑, 높은 성능을 가지지만 복잡하고 비용이 비싸다.
* Set Associative : 미리 정해준 특정 행에 있는 빈 공간에 저장한다. direct와 set의 중간의 성능이다.
### 캐시의 지역성에 대해 설명해 주세요.
* 시간 지역성 : 최근 사용된 데이터는 재참조될 가능성이 높다.
* 공간 지역성 : 접근한 데이터에 가까운 주소에 접근할 가능성이 높다. 블록 단위로 데이터에 접근하기에, 인접한 주소에 있는 데이터는 접근 시간을 줄일 수 있다.
### 캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.
* 이차원배열 내부의 1차원 배열끼리는 인접한 메모리 주소를 가진다. 그러므로 캐시의 지역성에 따라 내부의 1차원 배열을 먼저 탐색하는 가로 탐색을 먼저 하게 된다면, 더 높은 성능을 보인다.
### 캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?)
* cpu는 데이터를 페이지단위로 단위로 접근. 페이지에는 항상 인접한 데이터가 함께 저장되기에, 인접한 데이터가 캐시에 있을 수 있다.

## 메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)
* First-fit : 메모리를 순차적으로 검색하여, 요청된 프로세스 크기를 수용할 수 있는 첫 번째 빈 공간에 할당한다. 빠르지만, 메모리 앞 부분에 작은 빈 공간들이 많이 생길 수 있다.
* Best-fit : 요청된 프로세스 크기와 가장 근접하게 맞는, 남는 공간이 가장 적은 빈 공간에 할당한다. 메모리 활용은 효과적이지만, 적절한 공간을 찾는데에 시간이 소요된다.
* Worst-fit : 요청된 프로세스 크기를 수용할 수 있는 빈 공간 중에서 가장 큰 공간에 할당한다. 큰 빈 공간을 유지하려는 목적이다.
### worst-fit 은 언제 사용할 수 있을까요?
* 남는 공간을 크게 유지하여, 추후 다른 프로세스가 사용할 수 있도록 할 때.
### 성능이 가장 좋은 알고리즘은 무엇일까요?
* 메모리 효율성은 Best-fit, 속도는 First-fit. 실제로 First-fit이 가장 많이 사용된다.

## Thrashing 이란 무엇인가요?
* 잦은 페이지 교체로 페이지 폴트가 많이 발생하여 성능이 급격하게 저하되는 현상. 할당된 작업이 너무 많거나, 각 작업이 요구하는 메모리 양이 너무 많을 때발생한다.
### Thrashing 발생 시, 어떻게 완화할 수 있을까요?
* 적절한 페이지 교체 알고리즘의 선택, 지역성에 기반하여 자주 참조하는 페이지의 집합인 워킹셋을 메모리에 유지한다. 혹은 다중 프로세스 정도를 낮출 수 있다. 페이지 폴트 빈도를 주기적으로 조사하여 조절한다.

## 가상 메모리란 무엇인가요?
* 실제 메모리 주소가 아닌, 가상의 메모리 주소를 주는 방식이다. 이를 통해 이용 가능한 자원을 추상화하여 사용 할 수 있다. 또한 보조 기억 장치상의 비 활성 메모리를 결합하여 주 기억장치처럼 사용할수도 있다.
### 가상 메모리가 가능한 이유가 무엇일까요?
* 메모리 관리 단위인 페이지 또는 세그먼트를 통해 물리적 메모리와 보조 저장 장치 사이의 데이터를 스왑 할 수 있기 때문이다. 이로 인해 프로그램은 전체가 동시에 메모리에 적재될 필요가 없으며, 부분적으로 탑재되어도 괜찮아진다.
### Page Fault가 발생했을 때, 어떻게 처리하는지 설명해 주세요.
* Page Fault : 프로세스가 접근하려는 페이지가 메모리에 없을 때 발생하는 현상. 빈 프레임이 있다면 프레임에 메모리를 적재한다. 빈 프레임이 없다면 페이지 교체 알고리즘을 통해 사용하지 않는 페이지를 비우고, 적재한다.
### 페이지 크기에 대한 Trade-Off를 설명해 주세요.
* 페이지 크기가 클 경우 : 페이지 테이블 크기가 작아서 메모리 접근 시간이 감소하지만, 내부 단편화가 증가하여 메모리 낭비가 발생 할 수 있다.
* 페이지 크기가 작을 경우 : 내부 단편화가 줄어틀지만, 페이지 교체가 더 자주 발생 할 수 있어 메모리 접근 시간이 증가한다.
### 페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?
* 페이지 크기가 커지면 페이지 안에 다른 데이터가 있어 페이지 폴트가 증가 할 수 있다. 하지만 일정 이상으로 커지면 페이지 안에 필요한 데이터가 모두 있어 페이지 폴트가 감소 할 수 있다.
### 세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?
* 세그멘테이션을 사용하더라도 가상 메모리를 사용 할 수 있다.

## 세그멘테이션과 페이징의 차이점은 무엇인가요?
* 페이징 : 프로그램을 같은 크기의 페이지로 나누어 메모리에 할당. 내부 단편화 가능성이 있다. 물리적 메모리도 같은 크기의 프레임으로 나뉜다. 연속적이지 않은 페이지도 할당이 가능하기에 외부 단편화는 발생하지 않는다.
* 세그멘테이션 : 프로그램을 논리적 단위인 세그먼트로 나누어 메모리에 할당. 프로그램의 크기에 따라 가변적인 크기를 가진다. 프로그램의 할당이 해제 될 때 외부 단편화 문제가 발생할 수 있다. 메모리를 연속적으로 할당하기에 내부 단편화가 발생하지 않는다.
### 페이지와 프레임의 차이에 대해 설명해 주세요.
* 페이지와 프레임의 크기는 같다. 하지만 페이지는 논리적으로 나눈 단위이고, 프레임은 메모리상의 물리적인 단위이다.
### 내부 단편화와, 외부 단편화에 대해 설명해 주세요.
* 내부 단편화 : 메모리 단위 내부에 남는 부분이 생기며, 메모리에 낭비되는 공간이 생기는 경우.
* 외부 단편화 : 메모리 단위 외부에 남는 부분이 생겨 메모리에 남는 공간이 있음에도 새로운 프로세스가 할당되지 못하는 경우.
### 페이지에서 실제 주소를 어떤 장치 덕분에 알 수 있나요?
* MMU(메모리 관리 유닛)덕분에 알 수 있다. CPU와 물리 메모리 사이에서 가상주소를 물리 주소로 변환한다.
### 페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.
* 페이지 테이블의 페이지 번호와 오프셋(프레임 내에서의 물리적 위치)으로 구성된 가상주소를 사용한다. 페이지 번호를 통해 페이지 테이블에서 물리적 프레임 번호를 찾는다. 이후 프레임 번호와 페이지 오프셋이 결합되어 물리 주소를 얻을 수 있다.
### 어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?
* 페이지 테이블에 추가적으로 있는 접근권한을 통해 확인할 수 있다.
### 32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?
* 32비트에서는 2^32의 메모리 주소를 가질 수 있다. 페이지의 크기가 1kb, 2^10이므로 2^22개의 페이지 테이블이 존재 할 수 있다.
### 32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.
* 32비트시스템은 2^32개의 고유한 주소를 생성할 수 있는데, 이를 바이트로 표현하면 4GB이다.
### C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?
* 세그먼트 길이보다 큰 오프셋을 가진 주소에 접근하려고 할 때 발생한다. 또한 유효하지 않은 페이지에 접근하거나, 페이지 테이블에 정의되지 않은 주소에 접근하려고 할 때에도 발생한다.

## TLB는 무엇인가요?
* Translation Look-aside Buffer의 약자. 가상 메모리를 물리적인 주소로 변환하는 속도를 높이기 위해 사용되는 캐시. 자주 참조되는 가상 주소와 그에 해당하는 물리 주소의 매핑을 저장하여, 매번 페이지 테이블을 조회하지 않고도 주소 변환을 할 수 있게 도와준다. CPU 내부에 위치한 캐시 메모리의 일종.
### TLB를 쓰면 왜 빨라지나요?
* 페이지 테이블을 직접 조회하지 않고도 빠르게 메모리에 접근 할 수 있다.
### MMU가 무엇인가요?
* Memory Management Unit, 가상 메모리 주소를 실제 물리 메모리 주소로 변환하는 역할을 한다.
### TLB와 MMU는 어디에 위치해 있나요?
* CPU 내부에 위치한다.

## 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.
* Diabling Interrupts : 메모리에 값을 저장할 때, 이 과정동안 인터럽트를 꺼서 다른 쓰레드에게 방해받지 않도록 한다. 하지만 다른 중요한 작업에 응답 할 수 없게 되거나, 멀티코어에서는 불가능하다.
* Test - And - Set : 원자적 연산이며, 입력값을 테스트하여 그 값을 반환하며, 입력값은 True로 갱신한다. 입력값은 전역변수이다. 그렇기에 lock을 얻은 하나의 프로세스만 임계구역에 진입 할 수 있다는 점에서 상호배제를 만족한다.
* Compare-and-Swap : 주어진 값이 예상 값과 일치하는 경우에만 새로운 값으로 업데이트 하는 원자적 연산이다.
### volatile 키워드는 어떤 의미가 있나요?
* 변수가 예기치 않게 변경될 수 있음을 컴파일러에게 알리는 역할을 한다. 이 키워드를 사용하면 변수를 사용할 때 마다 최적화를 수행하지 않고 직접 메모리에서 값을 읽어온다. 이로 인해 가장 최근에 기록된 값을 읽는 것이 보장된다.
### 싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?
* 뮤텍스나 세마포어같은 락, 원자적 연산 등을 사용하여 동기화가 이루어 질 수 있다.
### memory barrier에 대해 알고계시나요?
* 프로그램이 실행 될 때 컴파일러가 최적화를 하기 위해 코드들의 순서를 변경한다. 이게 싱글쓰레드에선 문제가 되지 않지만, 멀티스레드에선 문제가 될 수 있기때문에 연산의 순서를 강제하도록 하는 기능.

## 페이지 교체 알고리즘에 대해 설명해 주세요.
* 가상 메모리 관리 기법이며, 사용하지 않는 페이지를 교체하는것.
* FIFO : 가장 먼저 온 페이지를 교체영역에 가장 먼저 놓는 방법
* LRU (Least Recently Used) : 참조된지 가장 오래된 페이지를 바꿈. 최적에 가깝다.
* LFU (Least Frequently Used) : 가장 참조 횟수가 적은 페이지를 교체
### LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?
* 시간 지역성을 활용한 알고리즘이다.
### LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?
* 연결리스트를 사용하거나, 연결리스트와 해시테이블을 합쳐서 구현해볼 수 있다. 이를 통해 순서를 유지하면서 페이지를 찾고, 교체하는데에 필요한 시간 복잡도를 O(1)로 구현 할 수 있다.
* 그 외의 방법은?
### Optimal Page Replacement 알고리즘에 대해 아시나요?
* 이론상으로 최적의 알고리즘. 미래를 예측하여 가장 오래 사용되지 않을 페이지를 교체한다.
### LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.
* 마지막으로 참조된 시간을 추적해야 하므로 메모리 접근마다 추가적인 오버헤드가 발생하고, 최근에 사용하지 않았다는 이유로 중요한 페이지가 교체될 가능성이 있다. LRU와 LFU를 고려하여 최근에 사용된 페이지와 자주 사용되는 페이지를 모두 고려 할 수 있여 중요한 페이지 교체를 방지 할 수 있고, Clock알고리즘을 통해 각 페이지에 사용됨 플래그를 설정해 순환하는 방식으로 LRU에 근사할 수 있다.
* Clock 알고리즘 : 각 페이지 엔트리는 사용됨 플래그가 있고, 사용된다면 1로 변경한다. 포인트라 순환형 리스트를 순회하며 1이라면 0으로 바꾸고, 0이라면 페이지를 교체한다.

## File Descriptor와, File System에 에 대해 설명해 주세요.
* File Descriptor : 유닉스 계열 시스템에서 프로세스가 파일이나 리소스에 접근할 때 사용하는 식별자. 프로세스가 실행 중에 파일을 열면 커널은 사용하지 않는 가장 작은 값을 할당해준다.
* File System : 컴퓨터에서 파일이나 데이터를 체계적으로 보관하고 쉽게 찾을 수 있도록 하는 체제. 커녈 영역에서 동작하며 파일의 물리적 위치와 이름, 디렉터리 구조, 메타데이터 등을 포함한다.
### I-Node가 무엇인가요?
* 유닉스 계열의 파일 시스템에서 사용되는 자료구조로, 파일의 종류, 크기, 소유권, 권한, 내용 등을 가진다. 파일이나 디렉토리는 고유한 I-Node 번호를 가지며 이 번호를 통해 파일 시스템이 해당 파일의 정보에 접근한다.
### File Descriptor와 I-Node가 어떻게 동작해서 파일이 열리는지?
* 파일 오픈 요청이 오면, 파일 시스템에서 요청된 파일의 아이노드를 찾고, 해당 파일에 대한 파일 디스크럽터를 할당받는다. 이후 아이노드에서 파일의 메타 데이터를 읽고 파일이 저장된 위치 정보를 얻어 파일을 열게된다.
### 디렉토리에는 어떤 정보들이 포함되어 있나요?
* 디렉토리도 파일이다. 하위 디렉토리나 파일에 대한 메타 데이터를 담고 있다.
### 프로그래밍 언어 상에서 제공하는 파일 관련 함수 (Python - open(), Java - BufferedReader/Writer 등)은, 파일을 어떤 방식으로 읽어들이나요?
* 파일을 열 때, 프로그램은 해당 파일에 대한 파일 디스크립터를 사용하여 파일에 접근한다. 닫을 때는 파일 디스크립터를 해제한다.
### 파일을 무한히 만들 수 있을까요?
* 파일 디스크립터 최대 개수 제한 있음

## 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.
* 동기와 비동기는 요청한 작업의 결과를 기다릴지 기다리지 않을지에 대한 것이고, 블로킹과 논블로킹은 작업을 요청하는동안 본래의 작업이 중지되는지 아닌지에 대한 것이다.
### 그렇다면, 동기이면서 논블로킹이고, 비동기이면서 블로킹인 경우는 의미가 있다고 할 수 있나요?
* 호출하는 함수의 결과를 확인하면서 다른 작업을 병행할 수 있는 경우에 동기-논블로킹이 쓰인다. 비동기 블로킹의 경우는 거의 쓰이지 않는다. 비동기인 경우에는, 논 블로킹을 통해 성능을 향상시킬 수 있고, 블로킹일 경우에는 어차피 작업이 중지되기에 동기화를 하는게 안전하다.
### I/O 멀티플렉싱에 대해 설명해 주세요.
* 한 스레드에서 여러 I/O 스트림을 동시에 관리하고, 사용 가능한 스트림에서 데이터를 처리하는 기술. 단일 스레드가 여러 I/O작업을 효율적으로 처리 할 수 있도록 한다.
### 논블로킹 I/O를 수행한다고 하면, 그 결과를 어떻게 수신할 수 있나요?
* 동기 방식에서는 주기적으로 체크하여 데이터 입력 여부를 체크함으로써 수신 할 수 있다. 비동기 방식에서는 콜백 함수를 통해 체크 할 수 있다.